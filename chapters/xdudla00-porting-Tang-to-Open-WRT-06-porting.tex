\chapter{Software portability}\label{porting}

Ideally, any software would be usable on any operating system, platform, and any processor architecture.
Existence of term "porting", derived from the Latin portāre which means "to~carry", proves that this ideal situation does not occurs that often, and acctual process of "carrying" software to system with different environment is most probably required.
Porting is process not documented and required if we want to run thing on another platform \cite{porting_software}.
Porting is also used to describe procces of converting computer games to became platform independent.

Software porting procces might be hard to distinguish with building software.
The reason might be that in many cases building software on desired platform is enough, when software application does not work "out of the box".
This kind of behavior, an application that works immediately after or even without any special installation and without need for any configuration or modification, is ideal.
It often happens when we copy application from one computer to another, not realizing that they have processors with same instructions set and same or very simmilar operating system therefore envoroment.
But let us be realistic, it depends on many things, such as processor architecture to which was application written (compiled), quality of design, how application is meant to be deployed and of course application's source code.

Number of significantly different central processor units (CPUs), and operating systems used on the desktop or server is much smaller than in the past.
Embeded ARM MIPS  RISC CISC x8664.

Nowadays, the goal should be to develop software which is portable between preferred computer platforms (Linux, UNIX, Apple, Microsoft).
If software is considered as not portable, it could not have to mean immediately that it is not possible, just that time and resources spent porting already written software are almost comparable, or even significantly higher than writing software as a whole from scratch.
Effort spent porting some software product to work on desired platform must be little, such as copying already installed files to usb flash drive and run it on another computer.
This kind of approach might most probably fail, due to not present dependencies of third party libraries not present on destination computer.
Despite dominance of the x86 architecture there is usually a need to recompile software running, not only on different operating systems, to make sure we have all the dependencies present.

To simplify portability, even on distinguished processors with distant instruction sets, modern compilers translate source code to a machine-independent intermediate code.
But still, in the embedded system market, where OpenWrt belongs to, porting remains a significant issue.

\section{OpenWrt's toolchain} %http://www.lemis.com/grog/Documentation/PUS/porting_unix_software-complete.pdf

Embeded devices are not meant for building on them because they does not have enough memory nor computation resorces as ordinary personal computers do.
Building on such device would be time consuming and may result to overheating, which could cause hardware to fail.
For this particular reason package building is done with cross-compiler.

Cross-compilation is done by set of tools called toolchain and it consists of:

\begin{itemize}
    \item compiler
    \item linker
    \item a C standard library
\end{itemize}

For porting to "target" (OpenWrt) system this toolchain has to be generated on "host" system.
The toolchain can be achieved in many different ways.
The easiest way is undoubtedly to find a .rpm (or .deb) package and have it installed on our "host" system.
If a binary package with desired toolchain is not available for your system or is not available at all, there might be need to compile a custom toolchain from scratch.% underline If this this case, tools like crosstool-ng may help.
In OpenWrt case we have available build system (buildroot) which is a set of Makefiles and patches capable of generating toolchain for devices that are supported by OpenWrt.
The OpenWrt's build system can also generate a root filesystem tightly bounded to target's enviroment.

There are many mirrors containg openwrt SDK buildroots but when developing upstream projet upstream build root might be best solution.
problems with SDKs on mirrors are that they are most likely outdated and dependencies required to make it possible to build on this SDK might be not possible to get on your platform


\subsection{Compiler}

In a nutshell compilers translate the high level programming language source code into lower level language such as machine understandable assembly instructions.
To do so compiler is performing many operations starting with preprocessing.

Preprocessing is

Lexical analysis,

Parsing,

Semantic analysis (syntax-directed translation),

Conversion of input programs to an intermediate representation,

Code optimization

Code generation

They can create binary executable files and object files.

Cross-compiler is programming tool capable of creating executable code that is supposed to run on a "target" architecture, in a similar or completely different enviroment, while working on a different "host" architecture.
Reason for using cross-compiling might be to separate the build environment from target environment as well.
OpenWrt toolchain uses gcc compiler, and it is one of the most important parts of toolchain.

\subsection{Linker}

bla ble bli

\subsection{C standard library}

The OpenWrt's cross-compilation toolchain uses musl, a tiny C standard library.

\section{OpenWrt's Buildroot}

The sysroot is a mere copy of the file system of your target platform.
Actually, you do not need to copy the entire file system on your host: the folders /usr and /lib would suffice.

It is a good idea to keep all these things gathered in a single place.
I suggest you create a folder (e.g. x-compile) and store the tool-chain and the sysroot in there.
Be tidy, because things can easily become a painful mess!


\subsection{Satisfy the dependencies}

When you start porting a code to a specific target platform, it is likely that the first problem you will face is to satisfy a few (many?) missing dependencies. This problem is easy to solve in principle, but can easily mess things up to a level you wouldn’t imagine.

If the code depends on some library that is NOT in the sysroot, there’s no way out but to find them somewhere, somehow. Dependencies can be satisfied in two ways: with static libraries or with shared libraries. If you are lucky, you could find a binary package providing what you need (i.e. the library files AND the header files), but most often you will have to cross-compile the source code on your own. Either ways, you end up with one or more binary files and a bunch of header files. Where to put them? Well, that depends. There are a few different situations that can happen, but basically everything reduces to two cases:

In the sysroot. If you are satisfying the dependencies with shared libraries (.so files) this is probably the most common solution (and maybe, the best solution). Remember that when everything will be up and running, these libraries must be installed somewhere in the file system of the target platform. So there is a natural answer to the question above: install them in the target sysroot, for example in /usr/lib (the binary shared files) and /usr/include (the header files). Or in any other path that allow the loader to find those libraries when the program executes. AND, install them in the file system of the actual target machine, in the same places, in order to make everything work as expected. Please note that static libraries (‘.a’ files) does not need to be installed in the target file system since their code is embedded in the executable file when you cross-compile a program.

In a different folder. This could be an interesting solution to keep the libraries that you cross-compiled on your own separated from the other libraries (for example, the system libraries). You can do that if you want (I often do that!) but if you do, you must remember to provide to compiler and linker programs with the paths where header files and binary files can be found. With static libraries, this information are only needed at compile and linking time, but if you are using shared libraries, this won’t suffice. You also must specify where these libraries can be found at run time.

Upstream Buildroot of OpenWrt is on github back then patches could been submitted by mailing list
it contains openwrt root, packages root, we will see how they are connected and how to use them.
But first we need to install all the dependencies that we need for this buildroot to be functional and ready to produce packages for our desired architecture on OpenWrt platform
Dependencies can be found on openwrt forum but i will list used depences on my system fedora 27

list dependencies and their versions

version of upstream buildroot is as mentioned important i have been working with upstream and all changes on upstream may affect your buildroot and maybe need to update dependency for buildroots
latest working upsream master commit that we were working with is ADD

we can clone build root from upstream with git Worflow should be to fork, clone forked copy to ourselves set upstream origin then when creating or wanting to edit any package we should create branch for this changes and then commit patches to this branch
when branch is ready create pull request and hope for the best that it wont be automatically revoked and just minor changes will be required.
after comunication with upstream and resolving all the possible issues our patch is ready to push to upstream.

where upstream changes are? how i can download ltest packages and what should i do to have them on my system?

\subsection{Working with buildroot}

describe buildroot topology and descibe what every single thing is what for
make will trigger making all packages not like in sdk
difference working with sdk and buildroot that sdk build only packages and buildroot can buld only package but it is designed to build entire image
for specified architecture respectively device from list
do not know how to add there new device but may provide link
configured with make menuconfig shown here firstly select architecture and configuration will be generated into .config :
in sdk .config is pre generated and make menuconfig (need to find out if possible)

on sdk make will trigger only building packages in directory package and it has to be done right way
it is also possible to do this with build root but is better to have upstream or own packages there in right directory

screen

make menuconfig is to select all packages which we want to build  todo findout if it is neccessary to buld base packages for selected

{\tt \$ make}

{\tt \$ feeds install -a}

tm tmp is needed if package directory has been edited to regenerate metadata of what (todo find out)

it is better to know what we are installig with feeds install and to choose only required packages for one newly choosed package to build

\subsection{Makefiles}

This is very important part of creating new packages therefore porting them to openwrt this file is similar to specfiles on fedora and

\begin{lstlisting}[language=c,basicstyle=\ttfamily\footnotesize,label=c,caption=Basic C code.]
    #include<stdio.h>
    #include<iostream>
    int main(void)
    {
        printf("Chello World\n");
        // comment
        return 0;
    }
\end{lstlisting}
