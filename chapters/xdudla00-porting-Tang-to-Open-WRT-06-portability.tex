\chapter{Software portability}\label{porting}

Ideally, any software would be usable on any operating system, platform, and any processor architecture.
Existence of term "porting", derived from the Latin portƒÅre which means "to~carry", proves that this ideal situation does not occurs that often, and acctual process of "carrying" software to system with different environment is most probably required.
Porting is process not documented and required if we want to run thing on another platform.
Porting is also used to describe procces of converting computer games to became platform independent.

Software porting procces might be hard to distinguish with building software.
The reason might be that in many cases building software on desired platform is enough, when software application does not work "out of the box".
This kind of behavior, an application that works immediately after or even without any special installation and without need for any configuration or modification, is ideal.
It often happens when we copy application from one computer to another, not realizing that they have processors with same instructions set and same or very simmilar operating system therefore envoroment.
But let us be realistic, it depends on many things, such as processor architecture to which was application written (compiled), quality of design, how application is meant to be deployed and of course application's source code.

Number of significantly different central processor units (CPUs), and operating systems used on the desktop or server is much smaller than in the past.
However on embeded devices there are still much more various architectures available ARM MIPS  RISC CISC x8664. \todo{TODO argh}

Nowadays, the goal should be to develop software which is portable between preferred computer platforms (Linux, UNIX, Apple, Microsoft).
If software is considered as not portable, it could not have to mean immediately that it is not possible, just that time and resources spent porting already written software are almost comparable, or even significantly higher than writing software as a whole from scratch.
Effort spent porting some software product to work on desired platform must be little, such as copying already installed files to usb flash drive and run it on another computer.
This kind of approach might most probably fail, due to not present dependencies of third party libraries not present on destination computer.
Despite dominance of the x86 architecture there is usually a need to recompile software running, not only on different operating systems, to make sure we have all the dependencies present.

To simplify portability, even on distinguished processors with distant instruction sets, modern compilers translate source code to a machine-independent intermediate code.
But still, in the embedded system market, where OpenWrt belongs to, porting remains a significant issue \cite{porting_software}.

\section{OpenWrt's toolchain}

Embeded devices are not meant for building on them because they does not have enough memory nor computation resorces as ordinary personal computers do(see Table \ref{routerspec}).
Building on such device would be time consuming and may result to overheating, which could cause hardware to fail.
For this particular reason package building is done with cross-compiler.

Cross-compilation is done by set of tools called toolchain and it consists of:
\begin{itemize}
    \item compiler
    \item linker
    \item a C standard library
\end{itemize}
For porting to "target" system (OpenWrt) this toolchain has to be generated on "host" system.
The toolchain can be achieved in many different ways.
The easiest way is undoubtedly to find a .rpm (or .deb) package and have it installed on our "host" system.
If a binary package with desired toolchain is not available for our system or is not available at all, there might be need to compile a custom toolchain from scratch.\footnote{tools like crosstool-ng (https://github.com/crosstool-ng/crosstool-ng) may help}

In case of OpenWrt we have available a set of Makefiles and patches called buildroot which is capable of generating toolchain.

\subsection{Compiler} \todo{rewrite section compiler}

In a nutshell compilers translate the high level programming language source code into lower level language such as machine understandable assembler instructions.
To do so compiler is performing many operations starting with preprocessing.

Preprocessing supports macro substitution and conditional compilation.
Typically the preprocessing phase occurs before syntactic or semantic analysis.
However, some languages such as Scheme\footnote{https://www.scheme.com/tspl4/} support macro substitutions based on syntactic forms.

Lexical analysis, also known as lexing or tokenization, breaks the source code text into a sequence of small pieces called lexical tokens.
Lexical analyzer does the scanning (cutting the input text into tokens and assign them a category) and the evaluating (converting tokens into a processed value).
Common token categories may include:
\begin{itemize}
    \item keywords (bound to programming language)
    \item identifiers (can not be keyword)
    \item separators
    \item operators
    \item literals
    \item comments
\end{itemize}
The set of token categories varies in different programming languages.
The lexeme syntax is typically a regular language, so a finite state automaton constructed from a regular expression can be used to recognize it.

Syntax analysis typically builds a parse tree structure according to the rules of a formal grammar which define the language's syntax.
The parse tree is often analyzed, augmented, and transformed by later phases in the compiler.

Semantic analysis checks parse tree and does type checking, object binding and definite assignment.
Output of semantic analysis is the symbol table or it results into rejecting incorrect programs or issuing warnings.

Code optimization, such as dead code elimination, inline expansion, constant propagation, loop transformation and even automatic parallelization, is done after analysis and it is independent on the CPU architecture.

Code generation is CPU dependent and does the transformation of intermediate language into the target machine language.
This involves resource and storage decisions, such as deciding which variables to fit into registers and memory and generating machine instructions along with their associated addressing modes.

Cross-compiler is programming tool capable of creating executable file that is supposed to run on a "target" architecture, in a similar or completely different enviroment, while working on a different "host" architecture.
It can also create object files used by linker.
Reason for using cross-compiling might be to separate the build environment from target environment as well.
OpenWrt toolchain uses gcc compiler, and it is one of the most important parts of toolchain.

\subsection{Linker}\todo{refactor}

With linker we are able to link compile's object files into single executable, library or object file.
Linker can do static linking and dynamic linking.

Static linking is the result of the linker copying all library routines used in the program into the executable image.
This may require more disk space and memory than dynamic linking, but is more portable, since it does not require the presence of the library on the system where it runs.
Static linking also prevents "DLL Hell", since each program includes exactly the versions of library routines that it requires, with no conflict with other programs. In addition, a program using just a few routines from a library does not require the entire library to be installed.

Dynamic linking is the process of postponing the resolving of some undefined symbols until a program is run.
That means that the executable code still contains undefined symbols, plus a list of objects or libraries that will provide definitions for these.
Loading the program will load these objects/libraries as well, and perform a final linking.
Dynamic linking needs no linker.

This approach offers two advantages:

Often-used libraries (for example the standard system libraries) need to be stored in only one location, not duplicated in every single binary.
If a bug in a library function is corrected by replacing the library, all programs using it dynamically will benefit from the correction after restarting them.
Programs that included this function by static linking would have to be re-linked first.
There are also disadvantages:

Known on the Windows platform as "DLL Hell", an incompatible updated library will break executables that depended on the behavior of the previous version of the library if the newer version is not properly backward compatible.
A program, together with the libraries it uses, might be certified (e.g. as to correctness, documentation requirements, or performance) as a package, but not if components can be replaced. (This also argues against automatic OS updates in critical systems; in both cases, the OS and libraries form part of a qualified environment.)

\subsection{C standard library}

Most common C standard libraries are: GNU Libc, uClibc musl-libc, or dietlibc.
They provide macros, type definitions and functions for tasks such as input/output processing (<stdio.h>), memory management (<stdlib.h), string handling (<string.h>), mathematical computations (<math.h>) and many more\footnote{https://en.wikipedia.org/wiki/C\_standard\_library\#Header\_files}.
The OpenWrt's cross-compilation toolchain uses musl-libc.

\section{OpenWrt's buildroot}

OpenWrt's buildroot is a build system capable of generating toolchain, and also a root filesystem (also called sysroot), enviroment tightly bound to target.
Build system can be configured for any device that is supported by OpenWrt.

The root filesystem in general is a mere copy of the file system of target's platform.
In many cases just having the folders /usr and /lib would be sufficient, therefore we do not need to copy nor create the entire target file system on our host .

It is a good idea to store all these things, the toolchain and the root filesystem in a single place.
With using OpenWrt's buildroot we will have this covered.
Be tidy and pedantic, because cross-compiling can easily become a painful mess!

\subsection{Buildroot prerequisites}

Let us demonstrate what are minimum requirements of space and size of RAM (Random Access Memory) for building packages for Openwrt using its buildroot.
For generating an installable OpenWrt firmware image file with a size of e.g. 8MB, we will need at least:
\begin{itemize}
\item ca. 200 MB for OpenWrt build system
\item ca. 300 MB for OpenWrt build system with OpenWrt Feeds
\item ca. 2.1 GB for source packages downloaded during build from the Feeds
\item ca. 3-4 GB to build (i.e. cross-compile) OpenWrt and generate the firmware file
\item ca. 1-4 GB of RAM to build Openwrt.(build x86's img need 4GB RAM)
\end{itemize}

These are specifications of embedded device TL-WR842Nv3 a regular wireless router manufactured by TP-LINK which was used to test all packages related to Tang server porting effort:

\begin{table}[h]
\centering
\label{routerspec}
\begin{tabular}{c|c}
\hline
Model           &   TL-WR842N(EU)                   \\ \hline
Version         &   v3                              \\ \hline
Architecture:   &   MIPS 24Kc                       \\ \hline
Manufacturer:   &   Qualcomm Atheros                \\ \hline
Bootloader:     &   U-Boot                          \\ \hline
System-On-Chip: &   Qualcomm Atheros QCA9531-BL3A   \\ \hline
CPU Speed:      &   650 MHz                         \\ \hline
Flash chip:     &   Winbond 25Q128CS16              \\ \hline
Flash size:     &   16 MiB                          \\ \hline
RAM chip:       &   Zentel A3R12E40CBF-8E           \\ \hline
RAM size:       &   64 MiB                          \\ \hline
Wireless:       &   Qualcomm Atheros QCA9531        \\ \hline
Antenae(s):     &   2 non-removable                 \\ \hline
Ethernet:       &   4 LAN, 1 WAN 10/100             \\ \hline
USB:            &   1 x 2.0                         \\ \hline
Serial:         &   ?                               \\ \hline
\end{tabular}
\caption{TL-WR842Nv3 specifications}
\end{table}

The actual sum of space required only for buildroot to work correctly which is about 6.4 GB compared to available storage space on wireless router should be demonstrative why is building for embedded devices done with cross-compiling.
The another reasons, not to just compare internal storage which might be extended (as shown on apendix TODOapendix), are device's minimalistic RAM size and not that "powerfull" CPU.\todo{add more about CPU}

\section{Prepare the enviroment}

Before getting to know buildroot we have to have host enviroment ready for buildroot in a way that we will install buildroot's dependencies and then buildroot itself.

\subsection{Buildroot's dependencies}

To be able to work with OpenWrt's bildroot we will need lots of buildroot dependencies first.
Please note that followning commands have to be run by user with root privileges to install buildroot dependencies on Fedora 27 system:

\begin{lstlisting}[language=bash,basicstyle=\ttfamily\footnotesize,label=fedora-dep-install,caption=Buildroot dependencies installation on Fedora 27]
    sudo dnf install binutils bzip2 gcc gcc-c++ \
    gawk gettext git-core flex ncurses-devel ncurses-compat-libs \
    zlib-devel zlib-static make patch unzip perl-ExtUtils-MakeMaker \
    perl-Thread-Queue  glibc glibc-devel glibc-static quilt sed \
    sdcc intltool sharutils bison wget openssl-devel
\end{lstlisting}
Some feeds might be not available over git but only via other versioning tools like subversion (svn) or mercurial.
If we want to obtain their source-code, we need to install svn and mercurial as well:
\begin{lstlisting}[language=bash,basicstyle=\ttfamily\footnotesize,label=fedora-ver-install,caption=Other versioning tools installation on Fedora 27]
    sudo dnf install subversion mercurial
\end{lstlisting}

\subsection{Getting buildroot}

There are mirrors containg OpenWrt SDK(Software development kit) buildroots for every released version of OpenWrt system.
It is good to consider using OpenWrt's SDK in order to build software application to only one specific release of target system.
For example when we are using "stable" release of OpenWrt 15.05.1 with codename "Chaos Calmer" on TL-WR842N(EU) device, we should probably end up in in "Supplementary Files" section of the OpenWrt archives
\footnote{https://archive.openwrt.org/chaos\_calmer/15.05.1/ar71xx/generic/} looking for SDK.

If we have host platform which aims to be on the bleeding edge of open-source technologies, such as OS Fedora, we will probably encounter issues with dependencies.
These issues are apearing because an older version of the dependencies are required for this old SDK to work and might be not available for our host platform anymore.
In this case we would have to install or even build older version of required packages to our host system.

When we start with porting an upstream projet (such as Tang) for latest release of target's sytem on Fedora host system, an upstream bleeding edge buildroot should be the best solution.
In our case we will work with latest OpenWrt release LEDE 17.01.4 on our target device, and download the OpenWrt bleeding edge (trunk version) buildroot with git.
To download OpenWrt buildroot from upstream repository run command:
\begin{lstlisting}[language=bash,basicstyle=\ttfamily\footnotesize,label=get-trunk,caption=Cloning upstream OpenWrt buildroot]
    git clone https://github.com/openwrt/openwrt.git ~\buildroot-openwrt
\end{lstlisting}

\section{Working with buildroot} \label{working-with-buildroot}

After we have enviroment ready to be worked on (all needed dependencies installed and buildroot downloaded on host) let us just remember these simple 4 rules to not break our enviroment in any way.

\begin{enumerate}
    \item Do everything in buildroot as non-root user!
    \item Issue all OpenWrt build system commands in the <buildroot> directory, \\e.g. \~/buildroot-openwrt/ % ~ is broken
    \item Do not build in a directory that has spaces in its full path.
    \item Change ownership of the directory where we downloaded \\the OpenWrt to other than root user
\end{enumerate}

It is good to set upstream...


describe buildroot topology and descibe what every single thing is what for

make will trigger making all packages not like in sdk

difference working with sdk and buildroot that sdk build only packages and buildroot can buld only package but it is designed to build entire image

for specified architecture respectively device from list

do not know how to add there new device but may provide link

configured with make menuconfig shown here firstly select architecture and configuration will be generated into .config :

in sdk .config is pre generated and make menuconfig (need to find out if possible)

on sdk make will trigger only building packages in directory package and it has to be done right way

it is also possible to do this with buildroot but is better to have upstream or own packages there in right directory

screen

make menuconfig is to select all packages which we want to build  todo findout if it is neccessary to buld base packages for selected

{\tt \$ make}

{\tt \$ feeds install -a}

tm tmp is needed if package directory has been edited to regenerate metadata of what (todo find out)

it is better to know what we are installig with feeds install and to choose only required packages for one newly choosed package to build

\section{Makefiles for OpenWrt's packages}

This is very important part of creating new packages therefore porting them to openwrt this file is similar to specfiles on fedora and

\begin{lstlisting}[language=c,basicstyle=\ttfamily\footnotesize,label=c,caption=Basic C code.]
    #include<stdio.h>
    #include<iostream>
    int main(void)
    {
        printf("Chello World\n");
        // comment
        return 0;
    }
\end{lstlisting}
