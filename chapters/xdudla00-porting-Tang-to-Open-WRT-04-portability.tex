\chapter{Software portability}\label{porting}

Ideally, any software would be usable on any operating system, platform, and any processor architecture.
Existence of term "porting", derived from the Latin portāre which means "to~carry", proves that this ideal situation does not occurs that often, and acctual process of "carrying" software to system with different environment is most probably required.
Porting is process not documented and required if we want to run thing on another platform.
Porting is also used to describe procces of converting computer games to became platform independent\cite{wiki_porting}.

Software porting procces might be hard to distinguish with building software.
The reason might be that in many cases building software on desired platform is enough, when software application does not work "out of the box".
This kind of behavior, an application that works immediately after or even without any special installation and without need for any configuration or modification, is ideal.
It often happens when we copy application from one computer to another, not realizing that they have processors with same instructions set and same or very simmilar operating system therefore envoroment.
But let us be realistic, it depends on many things, such as processor architecture to which was application written (compiled), quality of design, how application is meant to be deployed and of course application's source code.

Number of significantly different central processor units (CPUs), and operating systems used on the desktop or server is much smaller than in the past.
However on embeded devices there are still much more various architectures available ARM MIPS  RISC CISC x86\_64. \todo{TODO}

Nowadays, the goal should be to develop software which is portable between preferred computer platforms (Linux, UNIX, Apple, Microsoft).
If software is considered as not portable, it could not have to mean immediately that it is not possible, just that time and resources spent porting already written software are almost comparable, or even significantly higher than writing software as a whole from scratch.
Effort spent porting some software product to work on desired platform must be little, such as copying already installed files to usb flash drive and run it on another computer.
This kind of approach might most probably fail, due to not present dependencies of third party libraries not present on destination computer.
Despite dominance of the x86 architecture there is usually a need to recompile software running, not only on different operating systems, to make sure we have all the dependencies present.

To simplify portability, even on distinguished processors with distant instruction sets, modern compilers translate source code to a machine-independent intermediate code.
But still, in the embedded system market, where OpenWrt belongs to, porting remains a significant issue \cite{porting_software}.

\section{OpenWrt system}\label{owrt}
OpenWrt is is perhaps the most widely known Linux distribution for embedded devices especially for wireless routers.
It was originally developed in January 2004 for the Linksys WRT54G with buildroot from the uClibc project.
Now it supports many more models of routers.
OpenWrt is a registered trademark which is held by the Software in the Public Interest (SPI) in the name of the OpenWrt project.

Installing OpenWrt system means replacing your router’s built-in firmware with the Linux system which provides a fully writable filesystem with package management.
This means that we are not bound to applications provided by the vendor.
Router (the embedded device) with this distribution can be used for anything that an embedded Linux system can be used for, from using its SSH Server for SSH Tunneling, to running lightweight server software (e.g. IRC server) on it.
In fact it allows us to customize the device through the use of packages to suit any application.

\subsection{OpenWrt and LEDE}

The LEDE Project (“Linux Embedded Development Environment”) is a Linux operating system emerged from the OpenWrt project.
Its announcement was sent on 3th May 2016 by Jo-Philipp Wich to both the OpenWrt development list and the new LEDE development list\footnote{https://lwn.net/Articles/686180/}.
It describes LEDE as "a reboot of the OpenWrt community" and as "a spin-off of the OpenWrt project" seeking to create an embedded-Linux development community "with a strong focus on transparency, collaboration and decentralisation"\footnote{https://www.phoronix.com/scan.php?page=news\_item\&px=OpenWRT-Forked-As-LEDE}.

The rationale given for the reboot was that OpenWrt suffered from longstanding issues that could not be fixed from within—namely, regarding internal processes and policies.
For instance, the announcement said, the number of developers is at an all-time low, but there is no process for on-boarding new developers and, it seems, no process for granting commit access to new developers.

At the moment latest release of OpenWrt 15.05.1 (code-named "Chaos Calmer") released in March 2016.
LEDE developers continued to work separately on their upstream release and they delivered LEDE "Reboot" with version 17.01.0 on February 22nd 2017.

The remerge proposal vote was passed by LEDE developers in June 2017\footnote{http://lists.infradead.org/pipermail/lede-adm/2017-June/000552.html}.
After long and sometimes slowly moving discussions about the specifics of the re-merge, with multiple similar proposals but little subsequent action, formally announced on LEDE forum in January 2018\footnote{https://forum.lede-project.org/t/announcing-the-openwrt-lede-merge/10217}.
OpenWrt and LEDE projects agreed upon their unification under the OpenWrt name.
After merge OpenWrt upstream repository started to show signs of life.

Today (April 2018) the stable LEDE 17.01.4 "Reboot" release of OpenWrt released in October 2017 using Linux kernel version 4.4.92 runs on many routers.

% https://www.quora.com/What-is-the-difference-between-dd-wrt-and-open-wrt


\subsection{Why use OpenWrt}

Router is basically a full-blown computer that's always powered on, let us make some good use of it!
OpenWrt turns our router in a fully capable GNU/Linux computer, not just a network "magic" box.

OpenWrt system may be more stable than our hardware’s default firmware from vendor.
Not even that but probably more secure login with support of key-based SSH and less security holes since OpenWrt is regularly updated.

It is capable of running lightweight services like an IRC bouncer, a dyndns updater, print server, lighttpd even.
Some routers has USB ports so samba/ftp file sharing over the network comes into mind with an external HDD connected to it.

OpenWrt has an Web UI interface too so users less experienced in Linux could easily set up their network.
With OpenWrt we can tweak all the network settings such as QoS, Per-service bandwidth throttling, wireless isolation.
It is not bound to some "consumer-friendly" vendor-specific configuration of firewalling.
We are able to set up firewall and port-forwarding as we wish.
It provides load and bandwidth live graphs and we can monitor all outgoing/incoming connections.

The goal of this thesis would be to port a lightweight Tang daemon described in the chapter \ref{tang} Tang server to OpenWrt system.
Tang server will help us unlock our encrypted volumes while on safe home or office network without need for extra PC running it but having it on our tiny OpenWrt "server".
With Tang we do not have to care about typing passphrases over and over to unlock LUKS drives in safe enviroment.

\section{OpenWrt's toolchain}

Embeded devices are not meant for building on them because they does not have enough memory nor computation resorces as ordinary personal computers do(see Table \ref{routerspec}).
Building on such device would be time consuming and may result to overheating, which could cause hardware to fail.
For this particular reason package building is done with cross-compiler.

Cross-compilation is done by set of tools called toolchain and it consists of:
\begin{itemize}
    \item compiler
    \item linker
    \item a C standard library
\end{itemize}
For porting to "target" system (OpenWrt) this toolchain has to be generated on "host" system.
The toolchain can be achieved in many different ways.
The easiest way is undoubtedly to find a .rpm (or .deb) package and have it installed on our "host" system.
If a binary package with desired toolchain is not available for our system or is not available at all, there might be need to compile a custom toolchain from scratch.\footnote{tools like crosstool-ng (https://github.com/crosstool-ng/crosstool-ng) may help}

In case of OpenWrt we have available a set of Makefiles and patches called buildroot which is capable of generating toolchain.

\subsection{Compiler} \todo{rewrite section compiler}

In a nutshell compilers translate the high level programming language source code into lower level language such as machine understandable assembler instructions.
To do so compiler is performing many operations starting with preprocessing.

Preprocessing supports macro substitution and conditional compilation.
Typically the preprocessing phase occurs before syntactic or semantic analysis.
However, some languages such as Scheme\footnote{https://www.scheme.com/tspl4/} support macro substitutions based on syntactic forms.

Lexical analysis, also known as lexing or tokenization, breaks the source code text into a sequence of small pieces called lexical tokens.
Lexical analyzer does the scanning (cutting the input text into tokens and assign them a category) and the evaluating (converting tokens into a processed value).
Common token categories may include:
\begin{itemize}
    \item keywords (bound to programming language)
    \item identifiers (can not be keyword)
    \item separators
    \item operators
    \item literals
    \item comments
\end{itemize}
The set of token categories varies in different programming languages.
The lexeme syntax is typically a regular language, so a finite state automaton constructed from a regular expression can be used to recognize it.

Syntax analysis typically builds a parse tree structure according to the rules of a formal grammar which define the language's syntax.
The parse tree is often analyzed, augmented, and transformed by later phases in the compiler.

Semantic analysis checks parse tree and does type checking, object binding and definite assignment.
Output of semantic analysis is the symbol table or it results into rejecting incorrect programs or issuing warnings.

Code optimization, such as dead code elimination, inline expansion, constant propagation, loop transformation and even automatic parallelization, is done after analysis and it is independent on the CPU architecture.

Code generation is CPU dependent and does the transformation of intermediate language into the target machine language.
This involves resource and storage decisions, such as deciding which variables to fit into registers and memory and generating machine instructions along with their associated addressing modes.

Cross-compiler is programming tool capable of creating executable file that is supposed to run on a "target" architecture, in a similar or completely different enviroment, while working on a different "host" architecture.
It can also create object files used by linker.
Reason for using cross-compiling might be to separate the build environment from target environment as well.
OpenWrt toolchain uses gcc compiler, and it is one of the most important parts of toolchain.

\subsection{Linker}\todo{refactor}

With linker we are able to link compile's object files into single executable, library or object file.
Linker can do static linking and dynamic linking.

Static linking is the result of the linker copying all library routines used in the program into the executable image.
This may require more disk space and memory than dynamic linking, but is more portable, since it does not require the presence of the library on the system where it runs.
Static linking also prevents "DLL Hell", since each program includes exactly the versions of library routines that it requires, with no conflict with other programs. In addition, a program using just a few routines from a library does not require the entire library to be installed.

Dynamic linking is the process of postponing the resolving of some undefined symbols until a program is run.
That means that the executable code still contains undefined symbols, plus a list of objects or libraries that will provide definitions for these.
Loading the program will load these objects/libraries as well, and perform a final linking.
Dynamic linking needs no linker.

This approach offers two advantages:

Often-used libraries (for example the standard system libraries) need to be stored in only one location, not duplicated in every single binary.
If a bug in a library function is corrected by replacing the library, all programs using it dynamically will benefit from the correction after restarting them.
Programs that included this function by static linking would have to be re-linked first.
There are also disadvantages:

Known on the Windows platform as "DLL Hell", an incompatible updated library will break executables that depended on the behavior of the previous version of the library if the newer version is not properly backward compatible.
A program, together with the libraries it uses, might be certified (e.g. as to correctness, documentation requirements, or performance) as a package, but not if components can be replaced. (This also argues against automatic OS updates in critical systems; in both cases, the OS and libraries form part of a qualified environment.)

\subsection{C standard library}

Most common C standard libraries are: GNU Libc, uClibc musl-libc, or dietlibc.
They provide macros, type definitions and functions for tasks such as input/output processing (<stdio.h>), memory management (<stdlib.h), string handling (<string.h>), mathematical computations (<math.h>) and many more\footnote{https://en.wikipedia.org/wiki/C\_standard\_library\#Header\_files}.
The OpenWrt's cross-compilation toolchain uses musl-libc.

\section{OpenWrt's buildroot}

OpenWrt's buildroot is a build system capable of generating toolchain, and also a root filesystem (also called sysroot), enviroment tightly bound to target.
Build system can be configured for any device that is supported by OpenWrt.

The root filesystem in general is a mere copy of the file system of target's platform.
In many cases just having the folders /usr and /lib would be sufficient, therefore we do not need to copy nor create the entire target file system on our host .

It is a good idea to store all these things, the toolchain and the root filesystem in a single place.
With using OpenWrt's buildroot we will have this covered.
Be tidy and pedantic, because cross-compiling can easily become a painful mess!

\subsection{Buildroot prerequisites}

Let us demonstrate what are minimum requirements of space and size of RAM (Random Access Memory) for building packages for Openwrt using its buildroot.
For generating an installable OpenWrt firmware image file with a size of e.g. 8MB, we will need at least:
\begin{itemize}
\item ca. 200 MB for OpenWrt build system
\item ca. 300 MB for OpenWrt build system with OpenWrt Feeds
\item ca. 2.1 GB for source packages downloaded during build from the Feeds
\item ca. 3-4 GB to build (i.e. cross-compile) OpenWrt and generate the firmware file
\item ca. 1-4 GB of RAM to build Openwrt.(build x86's img need 4GB RAM)
\end{itemize}

These are specifications of embedded device TL-WR842Nv3 a regular wireless router manufactured by TP-LINK which was used to test all packages related to Tang server porting effort:

\begin{table}[h]
\centering
\label{routerspec}
\begin{tabular}{c|c}
\hline
Model           &   TL-WR842N(EU)                   \\ \hline
Version         &   v3                              \\ \hline
Architecture:   &   MIPS 24Kc                       \\ \hline
Manufacturer:   &   Qualcomm Atheros                \\ \hline
Bootloader:     &   U-Boot                          \\ \hline
System-On-Chip: &   Qualcomm Atheros QCA9531-BL3A   \\ \hline
CPU Speed:      &   650 MHz                         \\ \hline
Flash chip:     &   Winbond 25Q128CS16              \\ \hline
Flash size:     &   16 MiB                          \\ \hline
RAM chip:       &   Zentel A3R12E40CBF-8E           \\ \hline
RAM size:       &   64 MiB                          \\ \hline
Wireless:       &   Qualcomm Atheros QCA9531        \\ \hline
Antenae(s):     &   2 non-removable                 \\ \hline
Ethernet:       &   4 LAN, 1 WAN 10/100             \\ \hline
USB:            &   1 x 2.0                         \\ \hline
Serial:         &   ?                               \\ \hline
\end{tabular}
\caption{TL-WR842Nv3 specifications}
\end{table}

The actual sum of space required only for buildroot to work correctly which is about 6.4 GB compared to available storage space on wireless router should be demonstrative why is building for embedded devices done with cross-compiling.
The another reasons, not to just compare internal storage which might be extended (as shown on apendix TODOapendix), are device's minimalistic RAM size and not that "powerfull" CPU.\todo{add more about CPU}

\section{Prepare the enviroment}

Before getting to know buildroot we have to have host enviroment ready for buildroot in a way that we will install buildroot's dependencies and then buildroot itself.

\subsection{Buildroot's dependencies}

To be able to work with OpenWrt's bildroot we will need lots of buildroot dependencies first.
Please note that followning commands have to be run by user with root privileges to install buildroot dependencies on Fedora 27 system:
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
# dnf install binutils bzip2 gcc gcc-c++ \
gawk gettext git-core flex ncurses-devel ncurses-compat-libs \
zlib-devel zlib-static make patch perl-ExtUtils-MakeMaker \
perl-Thread-Queue  glibc glibc-devel glibc-static quilt sed \
sdcc intltool sharutils bison wget unzip openssl-devel
\end{lstlisting}
Some feeds might be not available over git but only via other versioning tools like subversion (svn) or mercurial.
If we want to obtain their source-code, we need to install svn and mercurial as well:
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
# dnf install subversion mercurial
\end{lstlisting}

\subsection{Getting buildroot}

There are mirrors containg OpenWrt SDK(Software development kit) buildroots for every released version of OpenWrt system.
It is good to consider using OpenWrt's SDK in order to build software application to only one specific release of target system.
For example when we are using "stable" release of OpenWrt 15.05.1 with codename "Chaos Calmer" on TL-WR842N(EU) device, we should probably end up in in "Supplementary Files" section of the OpenWrt archives
\footnote{https://archive.openwrt.org/chaos\_calmer/15.05.1/ar71xx/generic/} looking for SDK.

If we have host platform which aims to be on the bleeding edge of open-source technologies, such as OS Fedora, we will probably encounter issues with dependencies.
These issues are apearing because an older version of the dependencies are required for this old SDK to work and might be not available for our host platform anymore.
In this case we would have to install or even build older version of required packages to our host system.

When we start with porting an upstream projet (such as Tang) for latest release of target's sytem on Fedora host system, an upstream bleeding edge buildroot should be the best solution.
In our case we will work with latest OpenWrt release LEDE 17.01.4 on our target device, and download the OpenWrt bleeding edge (trunk version) buildroot with git.
To download OpenWrt buildroot from upstream repository run command:
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
\$ git clone https://github.com/openwrt/openwrt.git \ %TODO there is "\$ in pdf"
\end{lstlisting}

\section{Working with buildroot}\label{working-with-buildroot}

Working with Openwrt's buildroot requires some basic knowledge of the git version control system and processes of upstream project development using GitHub.

To save our work progress and be able to contribute to the upstream repository we should have a own fork of it.
A fork is a copy of a repository that we can manage.
It lets us make changes to a project without affecting the original (upstream) repository.
We can fetch updates from the upstream or submit changes to the original repository with pull requests.
These pull request are generated from the "devel" branch that we should have in our fork.
Figure \ref{fig:git-workflow} GitHub's workflow reflects this in a nutshell.
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{figures/placeholder.pdf}
    \caption{GitHub's workflow}
    \label{fig:git-workflow}
\end{figure}

To fork OpenWrt's buildroot we should have our GitHub account set up\footnote{https://github.com/join}, visit the OpenWrt's project upstream repository\footnote{https://github.com/openwrt/openwrt}, and click on "Fork" button in the top-right corner of the page.
Before cloning our fork it is recomended to set ut git enviroment\footnote{https://git-scm.com/book/en/v2/Getting-Started-First-Time-Git-Setup} on host machine and upload the SSH keys\footnote{https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/} to our account to minimize pushing effort to our fork.
All work related to this thesis has been done using GitHub account Tiboris\footnote{https://github.com/Tiboris/} therefore output of following commands are bound to it.
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
$ git clone https://github.com/Tiboris/openwrt.git \
    ~/buildroot-openwrt
\end{lstlisting}
Please note that this command will clone the {\it openwrt} repository of the GitHub user {\it Tiboris} to the {\it $\sim$/buildroot-openwrt} directory on our host.

To catch up with changes made upstream we should consider to configure a remote that points to it.
Configured remote allows us to sync changes made in the original repository with the fork and vice versa.
Make sure you are in the buildroot directory and add remote called upstream:
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
$ cd ~/buildroot-openwrt
$ git git remote add upstream https://github.com/openwrt/openwrt.git
\end{lstlisting}
To verify that remote is present run:
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
$ git remote -v
origin	git@github.com:Tiboris/openwrt.git (fetch)
origin	git@github.com:Tiboris/openwrt.git (push)
upstream	https://github.com/openwrt/openwrt.git (fetch)
upstream	https://github.com/openwrt/openwrt.git (push)
\end{lstlisting}
With the remote conficured correctly we can now sync with upstream repository.
To download latest upstream changes use the "fetch" option and  the "merge" option to aply them to our fork's branch.
\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
$ git fetch upstream master
remote: Counting objects: 4376, done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 4376 (delta 1776), reused 1775 (delta 1775), pack-reused 2599
Receiving objects: 100% (4376/4376), 1.27 MiB | 743.00 KiB/s, done.
Resolving deltas: 100% (2932/2932), completed with 809 local objects.
From https://github.com/openwrt/openwrt
 * branch                  master     -> FETCH_HEAD
   36fb0697e2..d089a5d773  master     -> upstream/master
$ git merge upstream/master
\end{lstlisting}

After we have enviroment ready to be worked on (all needed dependencies installed and fork of our buildroot downloaded on host system) let us just follow these simple 4 rules to not break our enviroment in any way.
\begin{enumerate}
    \item Do everything in buildroot as non-root user!
    \item Issue all OpenWrt build system commands in the <buildroot> directory, \\e.g. $\sim$/buildroot-openwrt/ % ~ is broken
    \item Do not build in a directory that has spaces in its full path.
    \item Change ownership of the directory where we downloaded \\the OpenWrt to other than root user
\end{enumerate}

\begin{lstlisting}[columns=fixed,tabsize=4,backgroundcolor=\color{yellow!10}]
https://git-scm.com/docs/gittutorial
\end{lstlisting}


describe buildroot topology and descibe what every single thing is what for

make will trigger making all packages not like in sdk

difference working with sdk and buildroot that sdk build only packages and buildroot can buld only package but it is designed to build entire image

for specified architecture respectively device from list

do not know how to add there new device but may provide link

configured with make menuconfig shown here firstly select architecture and configuration will be generated into .config :

in sdk .config is pre generated and make menuconfig (need to find out if possible)

on sdk make will trigger only building packages in directory package and it has to be done right way

it is also possible to do this with buildroot but is better to have upstream or own packages there in right directory

screen

make menuconfig is to select all packages which we want to build  todo findout if it is neccessary to buld base packages for selected

{\tt \$ make}

{\tt \$ feeds install -a}

tm tmp is needed if package directory has been edited to regenerate metadata of what (todo find out)

it is better to know what we are installig with feeds install and to choose only required packages for one newly choosed package to build
